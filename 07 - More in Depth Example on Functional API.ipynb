{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOug/rvFqxakbWjlUOExm0e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msaid1976/Aladdin-Persson-Machine-Learning-Collection/blob/master/7%20-%20More%20in%20Depth%20Example%20on%20Functional%20API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4kyvugHUiYb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "wkpASl23UvcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Pandas to load dataset from csv file\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pVGVTQEhUylN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPERPARAMETERS\n",
        "BATCH_SIZE = 64\n",
        "WEIGHT_DECAY = 0.001\n",
        "LEARNING_RATE = 0.001"
      ],
      "metadata": {
        "id": "V24G8DKeU2i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't get any GPU errors\n",
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "metadata": {
        "id": "GE6X4ryaU48h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_images = os.getcwd() + \"/train_images/\" + train_df.iloc[:, 0].values\n",
        "test_images = os.getcwd() + \"/test_images/\" + test_df.iloc[:, 0].values\n",
        "\n",
        "train_labels = train_df.iloc[:, 1:].values\n",
        "test_labels = test_df.iloc[:, 1:].values"
      ],
      "metadata": {
        "id": "dKBPgyJYU9ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_image(image, channels=1, dtype=tf.float32)\n",
        "\n",
        "    # In older versions you need to set shape in order to avoid error\n",
        "    # on newer (2.3.0+) the following 3 lines can safely be removed\n",
        "    image.set_shape((64, 64, 1))\n",
        "    label[0].set_shape([])\n",
        "    label[1].set_shape([])\n",
        "\n",
        "    labels = {\"first_num\": label[0], \"second_num\": label[1]}\n",
        "    return image, labels"
      ],
      "metadata": {
        "id": "Tzqeb4GUU_5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "id": "kZ9Jr8JGVEQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = (\n",
        "    train_dataset.shuffle(buffer_size=len(train_labels))\n",
        "    .map(read_image)\n",
        "    .batch(batch_size=BATCH_SIZE)\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "loJ6_8FqVGrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = (\n",
        "    test_dataset.map(read_image)\n",
        "    .batch(batch_size=BATCH_SIZE)\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "03XwD3d5VIXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(64, 64, 1))"
      ],
      "metadata": {
        "id": "Xo-K7EMlVLT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.Conv2D(\n",
        "    filters=32,\n",
        "    kernel_size=3,\n",
        "    padding=\"same\",\n",
        "    kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",
        ")(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = keras.activations.relu(x)\n",
        "x = layers.Conv2D(64, 3, kernel_regularizer=regularizers.l2(WEIGHT_DECAY),)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = keras.activations.relu(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Conv2D(\n",
        "    64, 3, activation=\"relu\", kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",
        ")(x)\n",
        "x = layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "output1 = layers.Dense(10, activation=\"softmax\", name=\"first_num\")(x)\n",
        "output2 = layers.Dense(10, activation=\"softmax\", name=\"second_num\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=[output1, output2])"
      ],
      "metadata": {
        "id": "NBgutIfGVOIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(LEARNING_RATE),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "ZI9guxcvVUUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=5, verbose=2)"
      ],
      "metadata": {
        "id": "4kCrHgycVXgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset, verbose=2)"
      ],
      "metadata": {
        "id": "WFlWT6h7VYt7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}